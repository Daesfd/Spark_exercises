{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d005a6df",
   "metadata": {},
   "source": [
    "# Como ver se um ano tem 53 semanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e73d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff92038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/05 18:56:15 WARN Utils: Your hostname, computador resolves to a loopback address: 127.0.1.1; using 10.0.0.135 instead (on interface wlp2s0)\n",
      "22/07/05 18:56:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/edson/spark/spark-3.0.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/07/05 18:56:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
    "    .config(\"spark.executor.memory\", \"500mb\") \\\n",
    "    .appName(\"Ex11\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fa52a4",
   "metadata": {},
   "source": [
    "## Criação de um df, com o id sendo o ano e o primeiro dia de cada ano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0988c3f",
   "metadata": {},
   "source": [
    "### x-1, pois queremos descobrir se a última semana do ano x-1 continua no ano x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80643328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(x-1, '01/01/' + str(x) + '') for x in range(1900, 2100)], ['Ano', 'Data_do_Ano'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "defd568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "| Ano|Data_do_Ano|\n",
      "+----+-----------+\n",
      "|1899| 01/01/1900|\n",
      "|1900| 01/01/1901|\n",
      "|1901| 01/01/1902|\n",
      "|1902| 01/01/1903|\n",
      "|1903| 01/01/1904|\n",
      "|1904| 01/01/1905|\n",
      "|1905| 01/01/1906|\n",
      "|1906| 01/01/1907|\n",
      "|1907| 01/01/1908|\n",
      "|1908| 01/01/1909|\n",
      "|1909| 01/01/1910|\n",
      "|1910| 01/01/1911|\n",
      "|1911| 01/01/1912|\n",
      "|1912| 01/01/1913|\n",
      "|1913| 01/01/1914|\n",
      "|1914| 01/01/1915|\n",
      "|1915| 01/01/1916|\n",
      "|1916| 01/01/1917|\n",
      "|1917| 01/01/1918|\n",
      "|1918| 01/01/1919|\n",
      "+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4b8d0",
   "metadata": {},
   "source": [
    "## Criação de uma coluna Data, transformando o tipo de dado para 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "627370d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('Data', to_date('Data_do_Ano', 'dd/MM/yyyy')).drop('Data_do_Ano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f086597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "| Ano|      Data|\n",
      "+----+----------+\n",
      "|1899|1900-01-01|\n",
      "|1900|1901-01-01|\n",
      "|1901|1902-01-01|\n",
      "|1902|1903-01-01|\n",
      "|1903|1904-01-01|\n",
      "|1904|1905-01-01|\n",
      "|1905|1906-01-01|\n",
      "|1906|1907-01-01|\n",
      "|1907|1908-01-01|\n",
      "|1908|1909-01-01|\n",
      "|1909|1910-01-01|\n",
      "|1910|1911-01-01|\n",
      "|1911|1912-01-01|\n",
      "|1912|1913-01-01|\n",
      "|1913|1914-01-01|\n",
      "|1914|1915-01-01|\n",
      "|1915|1916-01-01|\n",
      "|1916|1917-01-01|\n",
      "|1917|1918-01-01|\n",
      "|1918|1919-01-01|\n",
      "+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f55721",
   "metadata": {},
   "source": [
    "## Criação da coluna, a qual mostra o número da semana do dia 01-01 de cada ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "439dd0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('Num_da_semana_do_dia_01_01', weekofyear('Data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c79c7563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------------------------+\n",
      "| Ano|      Data|Num_da_semana_do_dia_01_01|\n",
      "+----+----------+--------------------------+\n",
      "|1899|1900-01-01|                         1|\n",
      "|1900|1901-01-01|                         1|\n",
      "|1901|1902-01-01|                         1|\n",
      "|1902|1903-01-01|                         1|\n",
      "|1903|1904-01-01|                        53|\n",
      "|1904|1905-01-01|                        52|\n",
      "|1905|1906-01-01|                         1|\n",
      "|1906|1907-01-01|                         1|\n",
      "|1907|1908-01-01|                         1|\n",
      "|1908|1909-01-01|                        53|\n",
      "|1909|1910-01-01|                        52|\n",
      "|1910|1911-01-01|                        52|\n",
      "|1911|1912-01-01|                         1|\n",
      "|1912|1913-01-01|                         1|\n",
      "|1913|1914-01-01|                         1|\n",
      "|1914|1915-01-01|                        53|\n",
      "|1915|1916-01-01|                        52|\n",
      "|1916|1917-01-01|                         1|\n",
      "|1917|1918-01-01|                         1|\n",
      "|1918|1919-01-01|                         1|\n",
      "+----+----------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678b1a7",
   "metadata": {},
   "source": [
    "## Filtração para ver os anos em que o numero da semana seja 53 e ver o total de anos com 53 semanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c1b2b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------------------------+\n",
      "| Ano|      Data|Num_da_semana_do_dia_01_01|\n",
      "+----+----------+--------------------------+\n",
      "|1903|1904-01-01|                        53|\n",
      "|1908|1909-01-01|                        53|\n",
      "|1914|1915-01-01|                        53|\n",
      "|1920|1921-01-01|                        53|\n",
      "|1925|1926-01-01|                        53|\n",
      "|1931|1932-01-01|                        53|\n",
      "|1936|1937-01-01|                        53|\n",
      "|1942|1943-01-01|                        53|\n",
      "|1948|1949-01-01|                        53|\n",
      "|1953|1954-01-01|                        53|\n",
      "|1959|1960-01-01|                        53|\n",
      "|1964|1965-01-01|                        53|\n",
      "|1970|1971-01-01|                        53|\n",
      "|1976|1977-01-01|                        53|\n",
      "|1981|1982-01-01|                        53|\n",
      "|1987|1988-01-01|                        53|\n",
      "|1992|1993-01-01|                        53|\n",
      "|1998|1999-01-01|                        53|\n",
      "|2004|2005-01-01|                        53|\n",
      "|2009|2010-01-01|                        53|\n",
      "+----+----------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('Num_da_semana_do_dia_01_01 = 53').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fdfc3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter('Num_da_semana_do_dia_01_01 = 53').count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
